{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37407ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: ATL\n",
      "       station             valid     mslp\n",
      "0          ATL  2021-06-03 00:00        M\n",
      "1          ATL  2021-06-03 00:05        M\n",
      "2          ATL  2021-06-03 00:10        M\n",
      "3          ATL  2021-06-03 00:15        M\n",
      "4          ATL  2021-06-03 00:20        M\n",
      "...        ...               ...      ...\n",
      "342308     ATL  2024-06-01 23:35        M\n",
      "342309     ATL  2024-06-01 23:40        M\n",
      "342310     ATL  2024-06-01 23:45        M\n",
      "342311     ATL  2024-06-01 23:50        M\n",
      "342312     ATL  2024-06-01 23:52  1018.60\n",
      "\n",
      "[342313 rows x 3 columns]\n",
      "Downloading: ATL\n",
      "       station             valid   tmpf\n",
      "0          ATL  2021-06-03 00:00      M\n",
      "1          ATL  2021-06-03 00:05      M\n",
      "2          ATL  2021-06-03 00:10      M\n",
      "3          ATL  2021-06-03 00:15      M\n",
      "4          ATL  2021-06-03 00:20      M\n",
      "...        ...               ...    ...\n",
      "342308     ATL  2024-06-01 23:35      M\n",
      "342309     ATL  2024-06-01 23:40      M\n",
      "342310     ATL  2024-06-01 23:45      M\n",
      "342311     ATL  2024-06-01 23:50      M\n",
      "342312     ATL  2024-06-01 23:52  75.00\n",
      "\n",
      "[342313 rows x 3 columns]\n",
      "       station             valid     mslp   tmpf\n",
      "0          ATL  2021-06-03 00:00        M      M\n",
      "1          ATL  2021-06-03 00:05        M      M\n",
      "2          ATL  2021-06-03 00:10        M      M\n",
      "3          ATL  2021-06-03 00:15        M      M\n",
      "4          ATL  2021-06-03 00:20        M      M\n",
      "...        ...               ...      ...    ...\n",
      "344268     ATL  2024-06-01 23:35        M      M\n",
      "344269     ATL  2024-06-01 23:40        M      M\n",
      "344270     ATL  2024-06-01 23:45        M      M\n",
      "344271     ATL  2024-06-01 23:50        M      M\n",
      "344272     ATL  2024-06-01 23:52  1018.60  75.00\n",
      "\n",
      "[344273 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example script that scrapes data from the IEM ASOS download service\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "#import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Python 2 and 3: alternative 4\n",
    "try:\n",
    "    from urllib.request import urlopen\n",
    "except ImportError:\n",
    "    from urllib2 import urlopen\n",
    "\n",
    "# Number of attempts to download data\n",
    "MAX_ATTEMPTS = 6\n",
    "# HTTPS here can be problematic for installs that don't have Lets Encrypt CA\n",
    "SERVICE = \"http://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?\"\n",
    "\n",
    "\n",
    "def download_data(uri):\n",
    "    \"\"\"Fetch the data from the IEM\n",
    "    The IEM download service has some protections in place to keep the number\n",
    "    of inbound requests in check.  This function implements an exponential\n",
    "    backoff to keep individual downloads from erroring.\n",
    "    Args:\n",
    "      uri (string): URL to fetch\n",
    "    Returns:\n",
    "      string data\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while attempt < MAX_ATTEMPTS:\n",
    "        try:\n",
    "            data = urlopen(uri, timeout=300).read().decode(\"utf-8\")\n",
    "            if data is not None and not data.startswith(\"ERROR\"):\n",
    "                return data\n",
    "        except Exception as exp:\n",
    "            print(\"download_data(%s) failed with %s\" % (uri, exp))\n",
    "            time.sleep(5)\n",
    "        attempt += 1\n",
    "\n",
    "    print(\"Exhausted attempts to download, returning empty data\")\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_stations_from_filelist():\n",
    "    \"\"\"Build a listing of stations from a simple file listing the stations.\n",
    "    The file should simply have one station per line.\n",
    "    \"\"\"\n",
    "    stations = []\n",
    "    for line in open(filename):\n",
    "        stations.append(line.strip())\n",
    "    return stations\n",
    "\n",
    "\n",
    "def get_stations_from_networks():\n",
    "    \"\"\"Build a station list by using a bunch of IEM networks.\"\"\"\n",
    "    stations = [\"ATL\"]\n",
    "    states = \"GA\"\n",
    "    # IEM quirk to have Iowa AWOS sites in its own labeled network\n",
    "    networks = [\"AWOS\"]\n",
    "    for state in states.split():\n",
    "        networks.append(\"%s_ASOS\" % (state,))\n",
    "\n",
    "    for network in networks:\n",
    "        # Get metadata\n",
    "        uri = (\n",
    "            \"https://mesonet.agron.iastate.edu/\" \"geojson/network/%s.geojson\"\n",
    "        ) % (network,)\n",
    "        data = urlopen(uri)\n",
    "        jdict = json.load(data)\n",
    "        for site in jdict[\"features\"]:\n",
    "            stations.append(site[\"properties\"][\"sid\"])\n",
    "    return stations\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    \"\"\"Our main method\"\"\"\n",
    "    # timestamps in UTC to request data for\n",
    "    startts = datetime.utcnow().date() - timedelta(days=1095)#datetime.datetime(2020, 6, 15)\n",
    "    endts   = datetime.utcnow().date()\n",
    "    \n",
    "    \n",
    "    # Two examples of how to specify a list of stations\n",
    "    #stations = get_stations_from_networks()\n",
    "    # stations = get_stations_from_filelist(\"mystations.txt\")\n",
    "    \n",
    "    stations = [\"ATL\"]\n",
    "    dfs = []   \n",
    "    data_types = [\"mslp\", \"tmpf\"]\n",
    "    for station in stations:\n",
    "        \n",
    "        for data_type in data_types:\n",
    "     \n",
    "            service = SERVICE + \"data=\"+data_type+\"&tz=Etc/UTC&format=onlytdf&=yes&\"\n",
    "\n",
    "            service += startts.strftime(\"year1=%Y&month1=%m&day1=%d&\")\n",
    "            service += endts.strftime(\"year2=%Y&month2=%m&day2=%d&\")\n",
    "    \n",
    "\n",
    "            \n",
    "            uri = \"%s&station=%s\" % (service, station)\n",
    "            print(\"Downloading: %s\" % (station,))\n",
    "            data = download_data(uri)\n",
    "            outfn = \"%s_%s_%s.txt\" % (\n",
    "                station,\n",
    "                startts.strftime(\"%Y%m%d%H%M\"),\n",
    "                endts.strftime(\"%Y%m%d%H%M\"),\n",
    "            )\n",
    "            out = open(outfn, \"w\")\n",
    "            out.write(data)\n",
    "            out.close()\n",
    "            \n",
    "            df = pd.read_csv(outfn, sep= '\\t' )\n",
    "\n",
    "\n",
    "            out.close()\n",
    "            dfs.append(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            df.head()\n",
    "            print(df)\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "    final_dataframe = pd.merge(dfs[0], dfs[1])\n",
    "    print(final_dataframe)\n",
    "    \n",
    "    final_dataframe.to_csv(\"mslp_temp.csv\",index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39685ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
