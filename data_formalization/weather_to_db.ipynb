{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from database import connect_to_db_upload\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format CVS\n",
    "def format_csv(csv_path):\n",
    "    # CSV file into a dataframe and format to have datetime and numeric columns\n",
    "    df = pd.read_csv(csv_path, names=['date','counts'])[1:] # Remove extra first row\n",
    "    df[\"date\"] = pd.to_datetime(df['date'])\n",
    "    df['date'] = df['date'].dt.tz_convert('UTC') # convert time zone to UTC\n",
    "    df = df.set_index('date')\n",
    "    df[\"counts\"] = df[\"counts\"].apply(pd.to_numeric)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather(my_station, enddt):\n",
    "    \"\"\"Main loop.\"\"\"\n",
    "    # print('Entered fetch_weather function')\n",
    "    # Step 1: Fetch global METAR geojson metadata\n",
    "    # https://mesonet.agron.iastate.edu/sites/networks.php\n",
    "    req = requests.get(\n",
    "        \"http://mesonet.agron.iastate.edu/geojson/network/AZOS.geojson\",\n",
    "        timeout=60,\n",
    "    )\n",
    "    geojson = req.json()\n",
    "    for feature in geojson[\"features\"]:\n",
    "        station_id = feature[\"id\"]\n",
    "        if station_id == my_station:\n",
    "            \n",
    "            props = feature[\"properties\"]\n",
    "            # We want stations with data to today (archive_end is null)\n",
    "            if props[\"archive_end\"] is None:\n",
    "                print('archive_end is null = data to today')\n",
    "\n",
    "            # print(f'Fetching data for station {station_id}')\n",
    "            uri = (\n",
    "                \"http://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?\"\n",
    "                f\"station={station_id}&data=tmpc&year1=1928&month1=1&day1=1&\"\n",
    "                f\"year2={enddt.year}&month2={enddt.month}&day2={enddt.day}&\"\n",
    "                \"tz=Etc%2FUTC&format=onlycomma&latlon=no&elev=no&missing=M&trace=T&\"\n",
    "                \"direct=yes&report_type=3\"\n",
    "            )\n",
    "            # print('uri: ', uri)\n",
    "\n",
    "            res = requests.get(uri, timeout=300)\n",
    "            # print('received response type: ', type(res))\n",
    "            return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_save_weather_table():\n",
    "\n",
    "    # Home directory\n",
    "    homedir = '../data/'\n",
    "    # Get station ids from detector settings\n",
    "    monitors = pd.read_csv('../detector_info_settings/detector_locations.csv')\n",
    "    ids = list(set(monitors['weather_station'].to_list()))\n",
    "    print('ids: ', ids)\n",
    "    \n",
    "    for my_station in ids:\n",
    "        print('Station id: ', my_station, ' counts: ', ids.count(my_station))\n",
    "        # If several detectors use same station, find the earliest date available\n",
    "        if ids.count(my_station) > 1 or my_station == 'ATL':\n",
    "            names = monitors.loc[monitors['weather_station'] == my_station, 'name'].to_list()\n",
    "            oldest_dates = []\n",
    "            for detector_name in names:\n",
    "                # If single level folder\n",
    "                try:\n",
    "                    detector_csv = f'{homedir}{detector_name}/{detector_name}_all_logs.csv'\n",
    "                    df = pd.read_csv(detector_csv)\n",
    "                    if 'Unnamed: 0' in df.columns.to_list():\n",
    "                        df = df.rename(columns={'Unnamed: 0':'date'})\n",
    "                    df['date'] = pd.to_datetime(df['date'])\n",
    "                    df = df.set_index('date')\n",
    "\n",
    "                    # get start and end dates of df\n",
    "                    df.sort_index(inplace=True)\n",
    "                    oldest_dates.append(df.head(1).index.values[0])\n",
    "\n",
    "                # Double level folder like Colombo and Serbia\n",
    "                except:\n",
    "                    if 'Det' in detector_name:\n",
    "                        subfolder = detector_name[-4:]\n",
    "                        folder = detector_name[:-5]\n",
    "                    else:\n",
    "                        subfolder = detector_name[-2:]\n",
    "                        folder = detector_name[:-3]\n",
    "                    \n",
    "                    detector_csv = f'{homedir}{folder}/{subfolder}/{detector_name}_all_logs.csv'\n",
    "                    df = pd.read_csv(detector_csv)\n",
    "                    if 'Unnamed: 0' in df.columns.to_list():\n",
    "                        df = df.rename(columns={'Unnamed: 0':'date'})\n",
    "                    df['date'] = pd.to_datetime(df['date'])\n",
    "                    df = df.set_index('date')\n",
    "\n",
    "                    # get start and end dates of df\n",
    "                    df.sort_index(inplace=True)\n",
    "                    oldest_dates.append(df.head(1).index.values[0])\n",
    "            \n",
    "            oldest_df = pd.DataFrame(oldest_dates, columns=['date'])\n",
    "            oldest_df.sort_values(by=['date'], inplace=True)\n",
    "            oldest = oldest_df.head(1)['date'].item()\n",
    "\n",
    "\n",
    "        # station for single monitor\n",
    "        else:\n",
    "            detector_name = monitors.loc[monitors['weather_station'] == my_station, 'name'].item()\n",
    "            detector_csv = f'{homedir}{detector_name}/{detector_name}_all_logs.csv'\n",
    "            df = pd.read_csv(detector_csv)\n",
    "            if 'Unnamed: 0' in df.columns.to_list():\n",
    "                df = df.rename(columns={'Unnamed: 0':'date'})\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            df = df.set_index('date')\n",
    "\n",
    "            # get start and end dates of df\n",
    "            df.sort_index(inplace=True)\n",
    "            oldest = df.head(1).index.values[0]\n",
    "    \n",
    "        print(f'oldest date: ', oldest)\n",
    "\n",
    "        # fetch\n",
    "        print(f'Entering fetching function for station {my_station}')\n",
    "        weatherjson = fetch_weather(my_station, date.today())\n",
    "        print('Done fetching')\n",
    "\n",
    "        wdf = pd.read_csv(StringIO(weatherjson.text), sep=',')\n",
    "        wdf[wdf=='M'] = np.nan\n",
    "\n",
    "        # Slice only for needed information based on dates - consider if temperature in farenheit\n",
    "        print('Columns: ', wdf.columns.to_list())\n",
    "        if 'tmpc' in wdf.columns.to_list():\n",
    "            wdf['tmpc'] = wdf['tmpc'].apply(pd.to_numeric)\n",
    "            wdf['tmpf'] = (wdf['tmpc'] * 9/5) + 32\n",
    "        \n",
    "        if 'mslp' in wdf.columns.to_list():\n",
    "            wdf['mslp'] = wdf['mslp'].apply(pd.to_numeric)\n",
    "            wdf = wdf.rename(columns={'valid':'date', 'tmpf':'temp_in_f', 'mslp':'sea_l_pressure_millibar'})\n",
    "        else:\n",
    "            wdf = wdf.rename(columns={'valid':'date', 'tmpf':'temp_in_f'})\n",
    "            wdf['sea_l_pressure_millibar'] = np.nan\n",
    "        \n",
    "        wdf['date'] = pd.to_datetime(wdf['date'])\n",
    "        wdf = wdf.drop(columns=['station'])\n",
    "        wdf = wdf.set_index('date')\n",
    "        wdf.sort_index(inplace=True)\n",
    "        wdf = wdf.loc[oldest:]\n",
    "        if wdf.duplicated(keep=False).any():\n",
    "            wdf = wdf.loc[wdf.duplicated(keep='last')]\n",
    "\n",
    "        engine, conn = connect_to_db_upload()\n",
    "\n",
    "        wdf.to_sql(\n",
    "            con=engine, name=f'{my_station.lower()}', if_exists='replace', index_label='date')\n",
    "        print(f'Table {my_station.lower()} sent to DB successfully')\n",
    "\n",
    "        # Make primary key for table via PSYCOPG2\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"\"\"ALTER TABLE {my_station.lower()} ADD PRIMARY KEY (date)\"\"\")\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        print('Query for primary key sent successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids:  ['CQT', 'LYBE', 'SKSM', 'VCRI', 'VCCC', 'ALM', 'DNAA', 'ATL']\n",
      "Station id:  ATL  counts:  1\n",
      "oldest date:  2019-01-17 21:00:00\n",
      "Entering fetching function for station ATL\n",
      "archive_end is null = data to today\n",
      "Done fetching\n",
      "Columns:  ['station', 'valid', 'tmpc']\n",
      "test:                        tmpc  temp_in_f  sea_l_pressure_millibar\n",
      "date                                                          \n",
      "2022-08-09 00:52:00  25.00     77.000                      NaN\n",
      "2022-08-09 01:52:00  25.00     77.000                      NaN\n",
      "2022-08-09 02:52:00  25.00     77.000                      NaN\n",
      "2022-08-09 03:52:00  23.89     75.002                      NaN\n",
      "2022-08-09 04:52:00  23.33     73.994                      NaN\n",
      "2022-08-09 05:52:00  22.78     73.004                      NaN\n",
      "2022-08-09 06:52:00  22.78     73.004                      NaN\n",
      "2022-08-09 07:52:00  22.78     73.004                      NaN\n",
      "2022-08-09 08:52:00  22.22     71.996                      NaN\n",
      "2022-08-09 09:52:00  22.22     71.996                      NaN\n",
      "2022-08-09 10:52:00  22.22     71.996                      NaN\n",
      "2022-08-09 11:52:00  22.78     73.004                      NaN\n",
      "2022-08-09 12:52:00  22.78     73.004                      NaN\n",
      "2022-08-09 13:52:00  22.78     73.004                      NaN\n",
      "2022-08-09 14:52:00  23.33     73.994                      NaN\n",
      "2022-08-09 15:52:00  23.33     73.994                      NaN\n",
      "2022-08-09 16:52:00  26.67     80.006                      NaN\n",
      "2022-08-09 17:52:00  30.00     86.000                      NaN\n",
      "2022-08-09 18:52:00  30.00     86.000                      NaN\n",
      "2022-08-09 19:52:00  31.67     89.006                      NaN\n",
      "2022-08-09 20:52:00  31.11     87.998                      NaN\n",
      "2022-08-09 21:52:00  29.44     84.992                      NaN\n",
      "2022-08-09 22:52:00  28.33     82.994                      NaN\n",
      "2022-08-09 23:50:00  24.00     75.200                      NaN\n",
      "Connected to muon database successfully\n",
      "Connected to muon database successfully\n",
      "Table atl sent to DB successfully\n",
      "Query for primary key sent successfully\n"
     ]
    }
   ],
   "source": [
    "download_and_save_weather_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
