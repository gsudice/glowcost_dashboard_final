{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from io import StringIO\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from database import connect_to_db_upload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format CVS\n",
    "def format_csv(csv_path):\n",
    "    # CSV file into a dataframe and format to have datetime and numeric columns\n",
    "    df = pd.read_csv(csv_path, names=['date','counts'])[1:] # Remove extra first row\n",
    "    df[\"date\"] = pd.to_datetime(df['date'])\n",
    "    df['date'] = df['date'].dt.tz_convert('UTC') # convert time zone to UTC\n",
    "    df = df.set_index('date')\n",
    "    df[\"counts\"] = df[\"counts\"].apply(pd.to_numeric)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather(my_station, enddt):\n",
    "    \"\"\"Main loop.\"\"\"\n",
    "    print('Entered fecth_weather function')\n",
    "    # Step 1: Fetch global METAR geojson metadata\n",
    "    # https://mesonet.agron.iastate.edu/sites/networks.php\n",
    "    req = requests.get(\n",
    "        \"http://mesonet.agron.iastate.edu/geojson/network/AZOS.geojson\",\n",
    "        timeout=60,\n",
    "    )\n",
    "    geojson = req.json()\n",
    "    for feature in geojson[\"features\"]:\n",
    "        station_id = feature[\"id\"]\n",
    "        if station_id == my_station:\n",
    "            \n",
    "            props = feature[\"properties\"]\n",
    "            # We want stations with data to today (archive_end is null)\n",
    "            if props[\"archive_end\"] is None:\n",
    "                print('archive_end is null = data to today')\n",
    "\n",
    "            print(f'Fetching data for station {station_id}')\n",
    "            uri = (\n",
    "                \"http://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?\"\n",
    "                f\"station={station_id}&data=tmpc&year1=1928&month1=1&day1=1&\"\n",
    "                f\"year2={enddt.year}&month2={enddt.month}&day2={enddt.day}&\"\n",
    "                \"tz=Etc%2FUTC&format=onlycomma&latlon=no&elev=no&missing=M&trace=T&\"\n",
    "                \"direct=yes&report_type=3\"\n",
    "            )\n",
    "            print('uri: ', uri)\n",
    "\n",
    "            res = requests.get(uri, timeout=300)\n",
    "            print('received response type: ', type(res))\n",
    "            return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chara_Muon002']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitors = pd.read_csv('../detector_info_settings/detector_locations.csv')\n",
    "detector_name = monitors.loc[monitors['weather_station'] == 'CQT', 'name'].to_list()\n",
    "detector_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_save_weather_table():\n",
    "\n",
    "    # Home directory\n",
    "    homedir = '../data/'\n",
    "    # Get station ids from detector settings\n",
    "    monitors = pd.read_csv('../detector_info_settings/detector_locations.csv')\n",
    "    ids = monitors['weather_station'].to_list()\n",
    "    \n",
    "    for id in ids:\n",
    "        if ids.count(id) > 1:\n",
    "            names = monitors.loc[monitors['weather_station'] == id, 'name'].to_list()\n",
    "\n",
    "        else:\n",
    "            detector_name = monitors.loc[monitors['weather_station'] == id, 'name'].item()\n",
    "            detector_csv = f'{homedir}{detector_name}/{detector_name}_all_logs.csv'\n",
    "            df = pd.read_csv(detector_csv)\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            df = df.set_index('date')\n",
    "            \n",
    "            # get start and end dates of df\n",
    "            df.sort_index(inplace=True)\n",
    "            oldest = df.head(1).index.values[0]\n",
    "            earliest = df.tail(1).index.values[0]\n",
    "            print(f'dates: ', oldest, earliest)\n",
    "\n",
    "    # list of files within selected monitor\n",
    "    all_files = listdir(homedir + detector_name.lower())\n",
    "    # filter based on ending being 'all_logs.csv'\n",
    "    detector_csv = [f for f in all_files if f.endswith('all_logs.csv')][0]\n",
    "    if len(detector_csv) == 0 and version != None:\n",
    "        more_files = listdir(homedir+detector_name.lower()+'/'+version.lower())\n",
    "        detector_csv = [f for f in more_files if f.endswith('all_logs.csv')][0]\n",
    "\n",
    "    # Get df and format\n",
    "    if version:\n",
    "        filesubpath = f'{homedir}{detector_name.lower()+'/'+version.lower()+'/'}'\n",
    "        df = pd.read_csv(homedir+detector_name.lower()+'/'+version.lower()+'/'+detector_csv)\n",
    "    else:\n",
    "        filesubpath = f'{homedir}{detector_name.lower()+'/'}'\n",
    "        df = pd.read_csv(homedir+detector_name+'/'+detector_csv)\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.set_index('date')\n",
    "    \n",
    "    # get start and end dates of df\n",
    "    df.sort_index(inplace=True)\n",
    "    oldest = df.head(1).index.values[0]\n",
    "    earliest = df.tail(1).index.values[0]\n",
    "    print(f'dates: ', oldest, earliest)\n",
    "\n",
    "    # fetch\n",
    "    # print(f'Entering function {my_station}')\n",
    "    weatherjson = fetch_weather(my_station, date.today())\n",
    "    # print('Done fetching')\n",
    "\n",
    "    # Store as csv and df\n",
    "    filename = f\"{filesubpath}{my_station}.csv\"\n",
    "    wdf = pd.read_csv(StringIO(weatherjson.text), sep=',')\n",
    "\n",
    "    # Slice only for needed information based on dates - consider if temperature in farenheit\n",
    "    print('Columns: ', wdf.columns.to_list())\n",
    "    if 'tmpc' in wdf.columns.to_list():\n",
    "        wdf['tmpf'] = (wdf['tmpc'] * 9/5) + 32\n",
    "    if 'mslp' in wdf.columns.to_list():\n",
    "        wdf = wdf.rename(columns={'valid':'date', 'tmpf':'temp_in_f', 'mslp':'sea_l_pressure_millibar'})\n",
    "    else:\n",
    "        wdf = wdf.rename(columns={'valid':'date', 'tmpf':'temp_in_f'})\n",
    "    wdf = wdf.drop(columns=['station'])\n",
    "\n",
    "    wdf = wdf.set_index('date')\n",
    "    wdf.sort_index(inplace=True)\n",
    "    wdf = wdf.loc[oldest:]\n",
    "\n",
    "    engine, conn = connect_to_db_upload()\n",
    "\n",
    "    wdf.to_sql(\n",
    "        con=engine, name=f'{my_station.lower()}', if_exists='replace', index_label='date')\n",
    "    print(f'Table {my_station.lower()} sent to DB successfully')\n",
    "\n",
    "    # Make primary key for table via PSYCOPG2\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"\"\"ALTER TABLE {my_station.lower()} ADD PRIMARY KEY (date)\"\"\")\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    print('Query for primary key sent successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weather data for detector Abuja\n",
      "dates:  2024-05-01T15:00:00.000000000 2024-08-21T03:00:00.000000000\n",
      "Entering function DNAA\n",
      "Entered fecth_weather function\n",
      "archive_end is null = data to today\n",
      "Fetching data for station DNAA\n",
      "uri:  http://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?station=DNAA&data=tmpc&year1=1928&month1=1&day1=1&year2=2024&month2=9&day2=3&tz=Etc%2FUTC&format=onlycomma&latlon=no&elev=no&missing=M&trace=T&direct=yes&report_type=3\n",
      "received response type:  <class 'requests.models.Response'>\n",
      "Done fetching\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station,valid,tmpc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNAA,2003-07-01 11:00,27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DNAA,2003-07-02 08:00,25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DNAA,2003-07-04 07:00,23.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            station,valid,tmpc\n",
       "0  DNAA,2003-07-01 11:00,27.00\n",
       "1  DNAA,2003-07-02 08:00,25.00\n",
       "2  DNAA,2003-07-04 07:00,23.00"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_and_save_weather_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station,valid,tmpc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68420</th>\n",
       "      <td>DNAA,2024-09-02 20:00,26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68421</th>\n",
       "      <td>DNAA,2024-09-02 21:00,25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68422</th>\n",
       "      <td>DNAA,2024-09-02 22:00,25.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                station,valid,tmpc\n",
       "68420  DNAA,2024-09-02 20:00,26.00\n",
       "68421  DNAA,2024-09-02 21:00,25.00\n",
       "68422  DNAA,2024-09-02 22:00,25.00"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abuja_wdf.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['station,valid,tmpc']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abuja_wdf.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['station'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m abuja_wdf \u001b[38;5;241m=\u001b[39m \u001b[43mabuja_wdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m abuja_wdf\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['station'] not found in axis\""
     ]
    }
   ],
   "source": [
    "abuja_wdf = abuja_wdf.drop('station')\n",
    "abuja_wdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
